# Large Language Model Repository

Welcome to the Large Language Model Repository! This repository serves as a space for my learning and practice in the realm of Large Language Models (LLMs), focusing on models such as BERT, T5, and GPT-2.

## Overview

This repository is dedicated to documenting and showcasing my progress in understanding and implementing state-of-the-art language models. As I delve into the intricacies of BERT, T5, GPT-2, and potentially other LLMs, I aim to share insights, code implementations, and resources that contribute to a better understanding of these powerful models.

## Contents

1. **BERT Implementation:** Explore my implementations and experiments with BERT, a pre-trained transformer model designed for natural language understanding tasks.

2. **T5 Experiments:** Delve into my T5 experiments, focusing on understanding the workings of Text-To-Text Transfer Transformer and its applications.

3. **GPT-2 Exploration:** Gain insights into my exploration of OpenAI's GPT-2, a generative pre-trained transformer model known for its creative text generation capabilities.

## How to Use

Feel free to navigate through the folders corresponding to each language model. You will find detailed explanations, code samples, and possibly Jupyter notebooks illustrating my journey in grasping the nuances of these models.

## Contributions

I welcome contributions, suggestions, and discussions! If you have insights, improvements, or questions related to my practice with LLMs, please don't hesitate to create an issue or submit a pull request.

Happy learning and exploring the fascinating world of Large Language Models!

**Note:** Ensure you have the necessary dependencies installed before running any code in this repository. Refer to individual model directories for specific instructions.

**Author:** Fahmi  
**Contact:** fahmiazizfadhil09@gmail.com  
**Date:** 25/12/2023
